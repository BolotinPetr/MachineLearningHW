{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее решение. Предсказываю окончание и число букв, которые нужно отрезать от слова-признака, чтобы добавив к ним предсказанной окончание получить ответ. Предсказываю в первую очередь те признаки, которые лучше всего предсказываются независимо, после чего использую их для предсказания следующего признака. Форма -> тип окончание -> число букв. Результаты отдельной кросс-валидации в файле contest3_finall_3. Из признаков добавляю тип первой буквы угаданного окончания, гласная или согласная. Логика в том, что чаще всего гласные и согласные чередуются, поэтому этот призкак может помочь. Он улучшил результат где-то на 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack, vstack, csc_matrix\n",
    "from nltk.stem import PorterStemmer\n",
    "import scipy as sc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from mlxtend.classifier import StackingClassifier, StackingCVClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import nltk\n",
    "import re\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_and_ending(X, y):\n",
    "    base = []\n",
    "    ending = []\n",
    "    flag = True\n",
    "    if len(X) >= len(y):\n",
    "        length = len(y)\n",
    "    else:\n",
    "        length = len(X)\n",
    "    for i in range(length):\n",
    "        if X[i] == y[i] and flag==True:\n",
    "            base.append(X[i])\n",
    "        else:\n",
    "            flag = False\n",
    "    ending = y.replace(''.join(base),\"\")\n",
    "    return ''.join(base), ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vowel_or_consonant(word):\n",
    "    alpha = word[-1] \n",
    "    if alpha == 'a' or alpha == 'e' or alpha == 'i' or alpha == 'o' or alpha =='u' or alpha == 'y':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(data):    \n",
    "    data = data.drop(['Id'], axis=1)\n",
    "    data = data.drop(0, axis=0)    \n",
    "    \n",
    "    form = []\n",
    "    for i in data.y:\n",
    "        form.append(i[-1])\n",
    "    data['form'] = form\n",
    "    \n",
    "    data['word'] = data.y.map(lambda x: re.sub(\"[+,V,A,N]\", \"\", x))\n",
    "    \n",
    "    base = []\n",
    "    ending = []\n",
    "    for X, y in zip(data.X, data.word):\n",
    "        b, e = base_and_ending(X, y)\n",
    "        base.append(b)\n",
    "        ending.append(e)\n",
    "    data['base'] = base\n",
    "    data['ending'] = ending\n",
    "    \n",
    "    end_length = []\n",
    "    for X, base in zip(data.X, data.base):        \n",
    "        end_length.append(len(X.replace(base,\"\")))\n",
    "    data['end_l'] = end_length\n",
    "    data = data.drop(['y'], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('task2_lemmas_train.txt', names=['Id', 'X', 'y'])\n",
    "test = pd.read_csv('task2_lemmas_test.txt', names=['Id', 'X'])\n",
    "sample = pd.read_csv('task2_lemmas_sample_submission.txt', names=['Id', 'Category'])\n",
    "\n",
    "train = transform_features(train)\n",
    "\n",
    "test = test.drop(['Id'], axis=1)\n",
    "test = test.drop(0, axis=0) \n",
    "\n",
    "sample = sample.drop(['Id'], axis=1)\n",
    "sample = sample.drop(0, axis=0)\n",
    "\n",
    "all_data = pd.concat([train, test], ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "form predicted\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(analyzer='char_wb', lowercase = True, ngram_range=(1, 8))\n",
    "X = cv.fit_transform(all_data.X)\n",
    "X_train, X_test = X[:len(train)], X[len(train):]\n",
    "clf = LogisticRegression(C=50)\n",
    "clf.fit(X_train, train.form)\n",
    "form_pred = clf.predict(X_test)\n",
    "print 'form predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending predicted\n"
     ]
    }
   ],
   "source": [
    "test['form'] = form_pred\n",
    "test = pd.get_dummies(test, columns=['form'])\n",
    "train = pd.get_dummies(train, columns=['form'])\n",
    "all_data = pd.concat([train, test])\n",
    "cv = CountVectorizer(analyzer='char_wb', ngram_range=(1, 7), lowercase = True)\n",
    "X = cv.fit_transform(all_data.X)\n",
    "X = csr_matrix(hstack([X, csr_matrix(all_data[['form_A','form_N','form_V']])]))\n",
    "X_train, X_test = X[:len(train)], X[len(train):]\n",
    "clf.fit(X_train, train['ending'])\n",
    "ending_pred = clf.predict(X_test)\n",
    "print 'ending predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>base</th>\n",
       "      <th>end_l</th>\n",
       "      <th>ending</th>\n",
       "      <th>form_A</th>\n",
       "      <th>form_N</th>\n",
       "      <th>form_V</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vergognerete</td>\n",
       "      <td>vergogn</td>\n",
       "      <td>5.0</td>\n",
       "      <td>are</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>vergognare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amnistiavate</td>\n",
       "      <td>amnistia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>re</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>amnistiare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>menomazione</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X         base  end_l ending  form_A  form_N  form_V  \\\n",
       "1  vergognerete      vergogn    5.0    are       0       0       1   \n",
       "2  amnistiavate     amnistia    4.0     re       0       0       1   \n",
       "3   menomazione  menomazione    0.0              0       1       0   \n",
       "\n",
       "          word  \n",
       "1   vergognare  \n",
       "2   amnistiare  \n",
       "3  menomazione  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея - сделать ещё один признак - первую букву окончания, потому что чаще в языке гласные и согласные буквы чередуются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'asd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dsa'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['ending'] = ending_pred\n",
    "all_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_or_c = []\n",
    "for ending in all_data.ending:\n",
    "    if len(ending) != 0:\n",
    "        v_or_c.append(vowel_or_consonant(ending[::-1]))\n",
    "    else:\n",
    "        v_or_c.append(10)\n",
    "all_data['v_or_c'] = v_or_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>base</th>\n",
       "      <th>end_l</th>\n",
       "      <th>ending</th>\n",
       "      <th>form_A</th>\n",
       "      <th>form_N</th>\n",
       "      <th>form_V</th>\n",
       "      <th>word</th>\n",
       "      <th>v_or_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vergognerete</td>\n",
       "      <td>vergogn</td>\n",
       "      <td>5.0</td>\n",
       "      <td>are</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>vergognare</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amnistiavate</td>\n",
       "      <td>amnistia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>re</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>amnistiare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfaldavamo</td>\n",
       "      <td>sfalda</td>\n",
       "      <td>4.0</td>\n",
       "      <td>re</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sfaldare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sfodererei</td>\n",
       "      <td>sfoder</td>\n",
       "      <td>4.0</td>\n",
       "      <td>are</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sfoderare</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X         base  end_l ending  form_A  form_N  form_V  \\\n",
       "1  vergognerete      vergogn    5.0    are       0       0       1   \n",
       "2  amnistiavate     amnistia    4.0     re       0       0       1   \n",
       "3   menomazione  menomazione    0.0              0       1       0   \n",
       "4    sfaldavamo       sfalda    4.0     re       0       0       1   \n",
       "5    sfodererei       sfoder    4.0    are       0       0       1   \n",
       "\n",
       "          word  v_or_c  \n",
       "1   vergognare       1  \n",
       "2   amnistiare       0  \n",
       "3  menomazione      10  \n",
       "4     sfaldare       0  \n",
       "5    sfoderare       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148301, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data, columns=['ending'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'X', u'base', u'end_l', u'form_A', u'form_N', u'form_V', u'word',\n",
       "       u'v_or_c', u'ending_', u'ending_a', u'ending_a-dati',\n",
       "       u'ending_a-estate', u'ending_a-gol', u'ending_a-italia',\n",
       "       u'ending_a-lavoro', u'ending_a-ordinanza', u'ending_a-paese',\n",
       "       u'ending_a-paga', u'ending_a-partito', u'ending_adonna',\n",
       "       u'ending_aforte', u'ending_an', u'ending_are', u'ending_arsi',\n",
       "       u'ending_asorte', u'ending_buono', u'ending_cere', u'ending_dere',\n",
       "       u'ending_desistere', u'ending_e', u'ending_e-quadro', u'ending_e-spia',\n",
       "       u'ending_edere', u'ending_enere', u'ending_enire', u'ending_ere',\n",
       "       u'ending_ernere', u'ending_essere', u'ending_ettere', u'ending_ge',\n",
       "       u'ending_gere', u'ending_gge', u'ending_ggere', u'ending_gliere',\n",
       "       u'ending_grande', u'ending_guere', u'ending_ia', u'ending_iare',\n",
       "       u'ending_igere', u'ending_imere', u'ending_ingere', u'ending_io',\n",
       "       u'ending_ire', u'ending_lere', u'ending_mpere', u'ending_ndere',\n",
       "       u'ending_nere', u'ending_nire', u'ending_o', u'ending_o-chiave',\n",
       "       u'ending_o-leninismo', u'ending_o-radar', u'ending_o-stato',\n",
       "       u'ending_oclan', u'ending_ogruppo', u'ending_olere', u'ending_olista',\n",
       "       u'ending_omorta', u'ending_ompee', u'ending_ompere', u'ending_ondere',\n",
       "       u'ending_opattuglia', u'ending_opraedere', u'ending_ore',\n",
       "       u'ending_orire', u'ending_otere', u'ending_oviro', u'ending_re',\n",
       "       u'ending_rere', u'ending_rire', u'ending_risedere', u'ending_rre',\n",
       "       u'ending_rsi', u'ending_scere', u'ending_scuotere', u'ending_si',\n",
       "       u'ending_ssr', u'ending_tere', u'ending_to', u'ending_ttere',\n",
       "       u'ending_uocere', u'ending_uoere', u'ending_uotere', u'ending_uovere',\n",
       "       u'ending_urre', u'ending_uscire', u'ending_vere', u'ending_x',\n",
       "       u'ending_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len predicted\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer='char_wb', ngram_range=(1, 10), lowercase = True, max_df=0.5)\n",
    "X = cv.fit_transform(all_data.X)\n",
    "X = csr_matrix(hstack([X, csr_matrix(all_data[['form_A','form_N','form_V', 'v_or_c', u'ending_', u'ending_a', u'ending_a-dati',\n",
    "                                               u'ending_a-estate', u'ending_a-gol', u'ending_a-italia',\n",
    "                                               u'ending_a-lavoro', u'ending_a-ordinanza', u'ending_a-paese',\n",
    "                                               u'ending_a-paga', u'ending_a-partito', u'ending_adonna',\n",
    "                                               u'ending_aforte', u'ending_an', u'ending_are', u'ending_arsi',\n",
    "                                               u'ending_asorte', u'ending_buono', u'ending_cere', u'ending_dere',\n",
    "                                               u'ending_desistere', u'ending_e', u'ending_e-quadro', u'ending_e-spia',\n",
    "                                               u'ending_edere', u'ending_enere', u'ending_enire', u'ending_ere',\n",
    "                                               u'ending_ernere', u'ending_essere', u'ending_ettere', u'ending_ge',\n",
    "                                               u'ending_gere', u'ending_gge', u'ending_ggere', u'ending_gliere',\n",
    "                                               u'ending_grande', u'ending_guere', u'ending_ia', u'ending_iare',\n",
    "                                               u'ending_igere', u'ending_imere', u'ending_ingere', u'ending_io',\n",
    "                                               u'ending_ire', u'ending_lere', u'ending_mpere', u'ending_ndere',\n",
    "                                               u'ending_nere', u'ending_nire', u'ending_o', u'ending_o-chiave',\n",
    "                                               u'ending_o-leninismo', u'ending_o-radar', u'ending_o-stato',\n",
    "                                               u'ending_oclan', u'ending_ogruppo', u'ending_olere', u'ending_olista',\n",
    "                                               u'ending_omorta', u'ending_ompee', u'ending_ompere', u'ending_ondere',\n",
    "                                               u'ending_opattuglia', u'ending_opraedere', u'ending_ore',\n",
    "                                               u'ending_orire', u'ending_otere', u'ending_oviro', u'ending_re',\n",
    "                                               u'ending_rere', u'ending_rire', u'ending_risedere', u'ending_rre',\n",
    "                                               u'ending_rsi', u'ending_scere', u'ending_scuotere', u'ending_si',\n",
    "                                               u'ending_ssr', u'ending_tere', u'ending_to', u'ending_ttere',\n",
    "                                               u'ending_uocere', u'ending_uoere', u'ending_uotere', u'ending_uovere',\n",
    "                                               u'ending_urre', u'ending_uscire', u'ending_vere', u'ending_x',\n",
    "                                               u'ending_y']])]))\n",
    "X_train, X_test = X[:len(train)], X[len(train):]\n",
    "clf.fit(X_train, train.end_l)\n",
    "ending_len_pred = clf.predict(X_test)\n",
    "print 'len predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in np.linspace(1, len(ending_len_pred), len(ending_len_pred)).astype(int):\n",
    "    cutted_word = test.X[i][:-ending_len_pred[i-1]] if ending_len_pred[i-1] > 0 else test.X[i]\n",
    "    predictions.append(cutted_word + ending_pred[i-1] + '+' + form_pred[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gettonare+V', 'incidentale+A', 'involtare+V', 'lievo+N', 'comunistizzare+V']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample['Category'] = predictions\n",
    "sample.to_csv('contest_3_submission6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
